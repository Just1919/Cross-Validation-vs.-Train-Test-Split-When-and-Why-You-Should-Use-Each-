{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Cross-Validation vs. Train/Test Split: When and Why You Should Use Each?**\n",
        "\n",
        "As you progress on your machine learning journey, you’ll learn that building a model isn’t just about training—it’s also about testing. Testing helps us evaluate how well a model performs on unseen data. But here’s the catch: if your test data isn’t truly representative, or if your dataset is too small, you might end up with misleading results.\n",
        "\n",
        "In this article, we’ll dive deep into:\n",
        "\n",
        "* The limitations of train_test_split\n",
        "*\tWhy small datasets are especially sensitive\n",
        "* How cross-validation comes to the rescue\n",
        "*\tWhen to use each strategy in practice\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**The Basics:** Why Do We Split the Data?\n",
        "\n",
        "Whenever you train a model, it’s crucial to evaluate it on a separate dataset. This helps you gauge how well it generalizes to new, unseen data not just the examples it was trained on.\n",
        "\n",
        "\n",
        "\n",
        "In Scikit-Learn, this is typically done using:\n",
        "\n"
      ],
      "metadata": {
        "id": "2wcgYsroD8rG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ou-pooRm_aQs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "It randomly splits the data into training and test sets. For example, you might allocate 80% of your data for training and 20% for testing.\n"
      ],
      "metadata": {
        "id": "n2EiFSkVFHTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A Real Example:** California Housing Dataset"
      ],
      "metadata": {
        "id": "1RwQ2_z1FSdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see how a simple model’s accuracy can vary just by changing how the data is split."
      ],
      "metadata": {
        "id": "-tzcY__GGSeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "df = fetch_california_housing(as_frame=True).frame\n",
        "df = shuffle(df, random_state=0)\n",
        "df = df.head(1200)  # Only use 1,200 rows\n"
      ],
      "metadata": {
        "id": "H-uZFBDa_pWY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s train a linear regression model:"
      ],
      "metadata": {
        "id": "DlN--0uYGMio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df.drop(['MedHouseVal'], axis=1)\n",
        "y = df['MedHouseVal']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "print(model.score(x_test, y_test))  # Output: ~0.68\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPr2nPkCAUw3",
        "outputId": "84f4e22c-10ce-4dd4-d0e3-c862a9a1b437"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6821178485035281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now change the seed:"
      ],
      "metadata": {
        "id": "gqdgX7vcGgOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "print(model.score(x_test, y_test))  # Output: ~0.70\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3QeQ3uwAy-7",
        "outputId": "e6bfd705-4056-4f28-c8a2-cf312eed4d02"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.700681942561586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, x, y, cv=5)\n",
        "print(scores.mean())  # Output: ~0.64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oqjePiiCFmg",
        "outputId": "fa23ec4b-26e8-4e50-d211-efeee58eaea5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6417227998432573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two different seeds, two different scores. So… is the model 68% accurate or 70% accurate?\n",
        "\n",
        "The truth is: **the smaller the dataset, the more sensitive your results are to how it’s split.**\n"
      ],
      "metadata": {
        "id": "p3ONzHH5GoUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Cross-Validation to the Rescue**\n",
        "\n",
        "Enter k-fold cross-validation.\n",
        "Instead of splitting once, we split the data into k equal parts (commonly 5 or 10), train the model on k-1 parts, and test it on the remaining part.\n",
        "\n",
        "This is repeated k times, and the scores are averaged.\n"
      ],
      "metadata": {
        "id": "B-KyO3xGG3tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, x, y, cv=5)\n",
        "print(scores.mean())  # Output: ~0.64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAQIJUMlCIaO",
        "outputId": "22029bd8-ca7a-42a4-c7d8-d11f2f4b3b91"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6417227998432573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This averaged score is more reliable because it smooths out the randomness of a single split."
      ],
      "metadata": {
        "id": "0qxpaDshHSnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus:** It uses all your data\n",
        "\n",
        "You don’t have to train a model before cross-validating it since cross_val_score trains it for you. However, cross_val_score trains a copy of the model, not the model itself, so once you’ve used cross-validation to gauge the model’s accuracy, you still need to call fit before making predictions:\n",
        "\n",
        "\n",
        "```\n",
        "model.fit(x, y)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YbPR4QmZHZjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have a validation or production test set, still test your model on completely unseen data at the very end to validate its performance.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A model’s performance metric is only as trustworthy as the data used to test it. For small datasets, relying on a single train/test split can lead to false confidence—or unwarranted pessimism. Cross-validation gives you a broader, more stable estimate of your model’s capabilities.\n"
      ],
      "metadata": {
        "id": "uDpRXmQ6HuiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find all the code and examples from this article on my GitHub repository: Just1919"
      ],
      "metadata": {
        "id": "K1U9RrypII-P"
      }
    }
  ]
}